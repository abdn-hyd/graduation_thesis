{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(normalized, min_val, max_val):\n",
    "    return ((normalized + 1) / 2) * (max_val - min_val) + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from JGC_MMN_dataloader import JGC_MMN_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 2 12 10\n"
     ]
    }
   ],
   "source": [
    "train_dataset = JGC_MMN_dataloader(\n",
    "        name=[\"long_term.npy\", \"short_term.npy\", \"ingredients.npy\", \"future.npy\", \"label.npy\"],\n",
    "        root=\"/Users/gunneo/Documents/4_2/Graduation_Thesis/Datasets/Beijing_House_Price_Dataset/JGC_MMN/train\",\n",
    "    )\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=36, shuffle=True)\n",
    "img_h = train_dataloader.dataset[0][0].shape[1]\n",
    "img_w = train_dataloader.dataset[0][0].shape[2]\n",
    "long_term_in_channels = train_dataloader.dataset[0][0].shape[0]\n",
    "short_term_in_channels = train_dataloader.dataset[0][1].shape[0]\n",
    "cur_ingred_dim = train_dataloader.dataset[0][2].shape[0]\n",
    "\n",
    "print(img_h, img_w, long_term_in_channels, short_term_in_channels, cur_ingred_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from JGC_MMN import JGC_MMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model = JGC_MMN(\n",
    "#     branches = [0, 1, 2],\n",
    "#     # img config\n",
    "#     img_h = img_h,\n",
    "#     img_w = img_w,\n",
    "#     # short term config\n",
    "#     short_term_in_channels = short_term_in_channels,\n",
    "#     short_term_growth_rate = 4,\n",
    "#     short_term_block_config = (9, 9, 9, 9, 9, 9),\n",
    "#     # long term config\n",
    "#     long_term_in_channels = long_term_in_channels,\n",
    "#     long_term_growth_rate = 4,\n",
    "#     long_term_block_config = (9, 9, 9, 9, 9, 9),\n",
    "#     # cur ingredient config\n",
    "#     cur_ingred_dim = cur_ingred_dim,\n",
    "#     emedding_dim = 64,\n",
    "#     # future price growth expectation config\n",
    "#     # fusion config\n",
    "#     modalities = 3,\n",
    "#     indexs = [0, 1],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. initialize train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD, RMSprop, Adagrad\n",
    "\n",
    "def rmse_loss(pred, target):\n",
    "    mse = nn.MSELoss()\n",
    "    return torch.sqrt(mse(pred, target))\n",
    "\n",
    "def train(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        w_path,\n",
    "        num_epochs=50,\n",
    "        optimizer_type='adam',\n",
    "        lr=5e-4,\n",
    "        input_indices=[0, 1, 2, 3],\n",
    "        patience=5,\n",
    "        save_interval=25,\n",
    "        loss_threshold=1e-4\n",
    "        ):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "        \n",
    "    optimizers = {\n",
    "        'adam': Adam(model.parameters(), lr=lr),\n",
    "        'sgd': SGD(model.parameters(), lr=lr, momentum=0.9),\n",
    "        'rmsprop': RMSprop(model.parameters(), lr=lr),\n",
    "        'adagrad': Adagrad(model.parameters(), lr=lr)\n",
    "    }\n",
    "    if optimizer_type not in optimizers:\n",
    "        raise ValueError(\"Unsupported optimizer type\")\n",
    "    optimizer = optimizers[optimizer_type]\n",
    "\n",
    "    best_model_path = os.path.join(w_path, \"best_model.pth\")\n",
    "    best_loss = float('inf')\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            inputs = [batch[i].to(device) for i in input_indices]\n",
    "            labels = batch[-1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = rmse_loss(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item() * labels.size(0)\n",
    "        \n",
    "        epoch_train_loss /= len(train_dataloader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {epoch_train_loss:.4f}\")\n",
    "\n",
    "        if abs(epoch_train_loss - best_loss) >= loss_threshold:\n",
    "            best_loss = epoch_train_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved to {best_model_path} with loss {best_loss:.4f}\")\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            print(f\"No improvement for {no_improve}/{patience} epochs\")\n",
    "            if no_improve > patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        if save_interval > 0 and (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = os.path.join(w_path, f\"checkpoint_{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(\n",
    "#     train_model,\n",
    "#     train_dataloader,\n",
    "#     w_path=\"/Users/gunneo/Documents/4_2/Graduation_Thesis/Datasets/Beijing_House_Price_Dataset/JGC_MMN/train_weights/\",\n",
    "#     num_epochs=500,\n",
    "#     optimizer_type='adam',\n",
    "#     lr=5e-3,\n",
    "#     input_indices=[0, 1, 2],\n",
    "#     patience=500,\n",
    "#     save_interval=25,\n",
    "#     loss_threshold=5e-4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# criterion = nn.MSELoss()\n",
    "# tanh = nn.Tanh()\n",
    "# num_batches = 0\n",
    "# rmse_total = 0.0\n",
    "# with torch.no_grad():\n",
    "#     for batch in train_dataloader:\n",
    "#         inputs = [batch[i].to(device) for i in [0, 1, 2]]\n",
    "#         labels = batch[-1].to(device)\n",
    "        \n",
    "#         predictions = train_model(inputs)\n",
    "#         # convert the normalized prediction back to the original scale\n",
    "#         print(predictions[0][0][14])\n",
    "#         print(labels[0][0][14])\n",
    "#         mse = criterion(predictions, tanh(labels))\n",
    "#         rmse = torch.sqrt(mse)\n",
    "#         rmse_total += rmse.item()\n",
    "#         num_batches += 1\n",
    "\n",
    "# average_rmse = rmse_total / num_batches\n",
    "# print(f\"Average RMSE: {average_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. test the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. global min-max normalization, indexs = [0, 1, 2], trained for 290 epochs, lr = 1e-3, \"adam\" optimizer, patience = 5, final loss for training set is 0.1860, test RMSE[-1, 1]: 0.3251001834869385\n",
    "\n",
    "2. global min-max normalization, indexs = [0, 1, 2], trained for 264 epochs, lr = 1e-3, \"adam\" optimizer, patience = 10, final loss for training set is 0.1346, test RMSE[-1, 1]: 0.269204705953598\n",
    "\n",
    "3. global min-max normalization, indexs = [0, 1, 2], trained for ? epochs, lr = 5e-3, \"adam\" optimizer, patience = 5, final loss for training set is 0.0911, test RMSE[-1, 1]: 0.21775959432125092\n",
    "\n",
    "4. global min-max normalization, indexs = [0, 1, 2], trained for 219 epochs, lr = 5e-3, \"adam\" optimizer, patience = 5, final loss for training set is 0.0892, test RMSE[-1, 1]: 0.21174463629722595\n",
    "\n",
    "5. global min-max normalization, indexs = [0, 1, 2], trained for 500(full training) epochs, lr = 5e-3, \"adam\" optimizer, patience = 500, final loss for training set is 0.0775, test RMSE[-1, 1]: 0.22640728950500488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = JGC_MMN_dataloader(\n",
    "        name=[\"long_term.npy\", \"short_term.npy\", \"ingredients.npy\", \"future.npy\", \"label.npy\"],\n",
    "        root=\"/Users/gunneo/Documents/4_2/Graduation_Thesis/Datasets/Beijing_House_Price_Dataset/JGC_MMN/test\",\n",
    "    )\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=12, shuffle=True)\n",
    "test_global_min = test_dataset.global_min\n",
    "test_global_max = test_dataset.global_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = JGC_MMN(\n",
    "    branches = [0, 1, 2],\n",
    "    # img config\n",
    "    img_h = img_h,\n",
    "    img_w = img_w,\n",
    "    # short term config\n",
    "    short_term_in_channels = short_term_in_channels,\n",
    "    short_term_growth_rate = 4,\n",
    "    short_term_block_config = (9, 9, 9, 9, 9, 9),\n",
    "    # long term config\n",
    "    long_term_in_channels = long_term_in_channels,\n",
    "    long_term_growth_rate = 4,\n",
    "    long_term_block_config = (9, 9, 9, 9, 9, 9),\n",
    "    # cur ingredient config\n",
    "    cur_ingred_dim = cur_ingred_dim,\n",
    "    emedding_dim = 64,\n",
    "    # future price growth expectation config\n",
    "    # fusion config\n",
    "    modalities = 3,\n",
    "    indexs = [0, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/8hm9fpxs3tdgdkp2z_jy1mr40000gn/T/ipykernel_14497/46752116.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_model.load_state_dict(torch.load(\"/Users/gunneo/Documents/4_2/Graduation_Thesis/Datasets/Beijing_House_Price_Dataset/JGC_MMN//weights_bak/4/best_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.load_state_dict(torch.load(\"/Users/gunneo/Documents/4_2/Graduation_Thesis/Datasets/Beijing_House_Price_Dataset/JGC_MMN//weights_bak/4/best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    test_model,\n",
    "    test_dataloader,\n",
    "    input_indexs = [0, 1, 2, 3]\n",
    "):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    test_model = test_model.to(device)\n",
    "    num_batches = 0\n",
    "    rmse_total = 0.0\n",
    "    conversion_rmse_total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            inputs = [batch[i].to(device) for i in input_indexs]\n",
    "            labels = batch[-1].to(device)\n",
    "            \n",
    "            predictions = test_model(inputs)\n",
    "            print(\"without conversion: \")\n",
    "            print(predictions[0][0][14])\n",
    "            print(labels[0][0][14])\n",
    "            rmse = rmse_loss(predictions, labels)\n",
    "            rmse_total += rmse.item()\n",
    "            print('------------------------------------')\n",
    "            print(\"with conversion: \")\n",
    "            predictions = inverse_normalize(predictions, test_global_min[-1], test_global_max[-1])\n",
    "            labels = inverse_normalize(labels, test_global_min[-1], test_global_max[-1])\n",
    "            print(predictions[0][0][14])\n",
    "            print(labels[0][0][14])\n",
    "            conversion_rmse = rmse_loss(predictions, labels)\n",
    "            conversion_rmse_total += conversion_rmse.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    average_rmse = rmse_total / num_batches\n",
    "    print(f\"Average RMSE: {average_rmse}\")\n",
    "    average_conversion_rmse = conversion_rmse_total / num_batches\n",
    "    print(f\"Average Conversion RMSE: {average_conversion_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without conversion: \n",
      "tensor([-0.6639, -0.6287, -0.9998, -0.6655, -0.8170, -0.4762, -0.8754, -0.7860,\n",
      "         0.0798, -0.0462,  0.2001,  0.1219,  0.1374, -0.1622, -0.4785, -0.1101,\n",
      "         0.1910, -0.1151, -0.0517, -0.2776,  0.1169, -0.5404, -0.6748, -0.3030,\n",
      "        -0.8263, -0.9657, -0.9259, -0.7056, -0.5707, -0.9909])\n",
      "tensor([-1.0000, -0.4420, -1.0000, -0.4529, -1.0000, -0.1551, -1.0000, -1.0000,\n",
      "         0.0600, -0.1786,  0.3060, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         0.1627, -0.1500, -0.3536, -0.2716, -0.0039, -1.0000, -1.0000, -0.4350,\n",
      "        -0.5826, -1.0000, -0.5114, -0.5083, -1.0000, -1.0000])\n",
      "------------------------------------\n",
      "with conversion: \n",
      "tensor([1.6507e+02, 1.8237e+02, 1.0452e-01, 1.6429e+02, 8.9871e+01, 2.5728e+02,\n",
      "        6.1211e+01, 1.0511e+02, 5.3036e+02, 4.6850e+02, 5.8946e+02, 5.5109e+02,\n",
      "        5.5870e+02, 4.1151e+02, 2.5614e+02, 4.3713e+02, 5.8501e+02, 4.3463e+02,\n",
      "        4.6581e+02, 3.5486e+02, 5.4862e+02, 2.2574e+02, 1.5974e+02, 3.4236e+02,\n",
      "        8.5326e+01, 1.6872e+01, 3.6384e+01, 1.4460e+02, 2.1086e+02, 4.4894e+00])\n",
      "tensor([  0.0000, 274.1000,   0.0000, 268.7500,   0.0000, 415.0000,   0.0000,\n",
      "          0.0000, 520.6667, 403.4500, 641.5000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000, 571.1250, 417.5000, 317.5000, 357.7857, 489.2778,\n",
      "          0.0000,   0.0000, 277.5000, 205.0000,   0.0000, 240.0000, 241.5000,\n",
      "          0.0000,   0.0000])\n",
      "Average RMSE: 0.21174465119838715\n",
      "Average Conversion RMSE: 104.00633239746094\n"
     ]
    }
   ],
   "source": [
    "test(test_model, test_dataloader, [0, 1, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
