{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_folder_path = \"../Datasets/Preprocessed_Dataset/img/\"\n",
    "# ids_list = [int(d) for d in os.listdir(img_folder_path) if os.path.isdir(os.path.join(img_folder_path, d))]\n",
    "# len(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_dataset_path = \"../Datasets/Melbourne_House_Price_Dataset/\"\n",
    "csv_files = [\"Propery_Basic.csv\", \"Property_full_Table.csv\", \"Property_Features.csv\", \"Property_Address.csv\"]\n",
    "mapping_files = [\"Mapping_SA1.csv\", \"Mapping_School.csv\", \"Mapping_Train_Station.csv\"]\n",
    "public_files = [\"SA1_Satistics.csv\", \"School.csv\", \"School_ranking.csv\", \"Train_Station.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(property_dataset_path + csv_files[2])\n",
    "# df['ID'] = df['ID'].apply(lambda x: int(str(x)[:-2]) if isinstance(x, str) else x)\n",
    "# df.to_csv(property_dataset_path + csv_files[2], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for csv_file in csv_files:\n",
    "#     try:\n",
    "#         df = pd.read_csv(property_dataset_path + csv_file)\n",
    "#     except Exception as e:\n",
    "#         print(\"failed to read {}\".format(csv_file))\n",
    "#         continue\n",
    "\n",
    "#     if 'ID' not in df.columns:\n",
    "#         print(f\"warn: {csv_file} did not have 'id' col, skip.\")\n",
    "#         continue\n",
    "\n",
    "#     filtered_df = df[df['ID'].isin(ids_list)]    \n",
    "#     filtered_df.to_csv(property_dataset_path + csv_file, index=False)\n",
    "#     print(f\"{csv_file} processed, remains: {len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_sets = []\n",
    "# for file in csv_files:\n",
    "#     df = pd.read_csv(property_dataset_path + file)\n",
    "#     ids = set(df['ID'])\n",
    "#     id_sets.append(ids)\n",
    "#     print(f\"{file} processed, remains: {len(ids)}\")\n",
    "\n",
    "# common_ids = set.intersection(*id_sets)\n",
    "# print(f\"number of intersection of ID: {len(common_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_ids_list = list(common_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in csv_files:\n",
    "#     df = pd.read_csv(property_dataset_path + file)\n",
    "\n",
    "#     df_filtered = df[df['ID'].isin(common_ids_list)]\n",
    "    \n",
    "#     df_filtered.to_csv(property_dataset_path + file, index=False)\n",
    "#     print(f\"{file} filtered, remains: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in mapping_files:\n",
    "#     df = pd.read_csv(property_dataset_path + file)\n",
    "\n",
    "#     df_filtered = df[df['id1'].isin(common_ids_list)]\n",
    "    \n",
    "#     df_filtered.to_csv(property_dataset_path + file, index=False)\n",
    "#     print(f\"{file} filtered, remains: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_sets_1 = []\n",
    "# for file in mapping_files:\n",
    "#     df = pd.read_csv(property_dataset_path + file)\n",
    "    \n",
    "#     ids = set(df['id1'])\n",
    "#     id_sets_1.append(ids)\n",
    "#     print(f\"{file} processed, remains: {len(ids)}\")\n",
    "\n",
    "# common_ids_1 = set.intersection(*id_sets_1)\n",
    "# print(f\"number of intersection of ID: {len(common_ids_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_ids_list_1 = list(common_ids_1)\n",
    "# for file in csv_files:\n",
    "#     df = pd.read_csv(property_dataset_path + file)\n",
    "\n",
    "#     df_filtered = df[df['ID'].isin(common_ids_list_1)]\n",
    "    \n",
    "#     df_filtered.to_csv(property_dataset_path + file, index=False)\n",
    "#     print(f\"{file} filtered, remains: {len(df_filtered)}\")\n",
    "\n",
    "# for file in mapping_files:\n",
    "#     df = pd.read_csv(property_dataset_path + file)\n",
    "\n",
    "#     df_filtered = df[df['id1'].isin(common_ids_list_1)]\n",
    "    \n",
    "#     df_filtered.to_csv(property_dataset_path + file, index=False)\n",
    "#     print(f\"{file} filtered, remains: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SA1\n",
    "# df_mapping_sa1 = pd.read_csv(property_dataset_path + mapping_files[0])\n",
    "# sa1_ids = list(set(df_mapping_sa1[\"id2\"]))\n",
    "# df_sa1 = pd.read_csv(property_dataset_path + public_files[0])\n",
    "# sa1_ids_old = list(set(df_sa1[\"ID\"]))\n",
    "# print(len(sa1_ids))\n",
    "# print(len(sa1_ids_old))\n",
    "# df_sa1_filtered = df_sa1[df_sa1['ID'].isin(sa1_ids)]\n",
    "# df_sa1_filtered.to_csv(property_dataset_path + public_files[0], index=False)\n",
    "# print(f\"{public_files[0]} filtered, remains: {len(df_sa1_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # school\n",
    "# df_mapping_school = pd.read_csv(property_dataset_path + mapping_files[1])\n",
    "# school_ids = list(set(df_mapping_school[\"id2\"]))\n",
    "# df_school = pd.read_csv(property_dataset_path + public_files[1])\n",
    "# school_ids_old = list(set(df_school[\"ID\"]))\n",
    "# print(len(school_ids))\n",
    "# print(len(school_ids_old))\n",
    "# df_school_filtered = df_school[df_school['ID'].isin(school_ids)]\n",
    "# df_school_filtered.to_csv(property_dataset_path + public_files[1], index=False)\n",
    "# print(f\"{public_files[1]} filtered, remains: {len(df_school_filtered)}\")\n",
    "\n",
    "# df_school_ranking = pd.read_csv(property_dataset_path + public_files[2])\n",
    "# school_ranking_ids_old = list(set(df_school_ranking[\"school_ID\"]))\n",
    "# print(len(school_ids))\n",
    "# print(len(school_ranking_ids_old))\n",
    "# df_school_ranking_filtered = df_school_ranking[df_school_ranking['school_ID'].isin(school_ids)]\n",
    "# df_school_ranking_filtered.to_csv(property_dataset_path + public_files[2], index=False)\n",
    "# print(f\"{public_files[2]} filtered, remains: {len(df_school_ranking_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train\n",
    "# df_mapping_train_station = pd.read_csv(property_dataset_path + mapping_files[2])\n",
    "# train_station_ids = list(set(df_mapping_train_station[\"stop_id\"]))\n",
    "# df_train_station = pd.read_csv(property_dataset_path + public_files[3])\n",
    "# train_station_ids_old = list(set(df_train_station[\"stop_id\"]))\n",
    "# print(len(train_station_ids))\n",
    "# print(len(train_station_ids_old))\n",
    "# df_train_station_filtered = df_train_station[df_train_station['stop_id'].isin(train_station_ids)]\n",
    "# df_train_station_filtered.to_csv(property_dataset_path + public_files[3], index=False)\n",
    "# print(f\"{public_files[3]} filtered, remains: {len(df_train_station_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move redundant images\n",
    "# df = pd.read_csv(property_dataset_path + csv_files[0])\n",
    "# ids_list = list(set(df[\"ID\"]))\n",
    "# img_ids_list = [int(d) for d in os.listdir(img_folder_path) if os.path.isdir(os.path.join(img_folder_path, d))]\n",
    "# extra_img_ids = [img_id for img_id in img_ids_list if img_id not in ids_list]\n",
    "\n",
    "# move_folder_path = os.path.join(property_dataset_path, \"house_price_redundant_dataset/\")\n",
    "\n",
    "# for extra_img_id in extra_img_ids:\n",
    "#     src_path = os.path.join(img_folder_path, str(extra_img_id))\n",
    "#     dest_path = os.path.join(move_folder_path, str(extra_img_id))\n",
    "#     try:\n",
    "#         shutil.move(src_path, dest_path)\n",
    "#         print(f\"moved {extra_img_id} to {move_folder_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"moved {extra_img_id} error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 45857 tranaction records to be used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_dataset_path = \"../Datasets/Melbourne_House_Price_Dataset/\"\n",
    "csv_files = [\"Propery_Basic.csv\", \"Property_full_Table.csv\", \"Property_Features.csv\", \"Property_Address.csv\"]\n",
    "mapping_files = [\"Mapping_SA1.csv\", \"Mapping_School.csv\", \"Mapping_Train_Station.csv\"]\n",
    "public_files = [\"SA1_Satistics.csv\", \"School.csv\", \"School_ranking.csv\", \"Train_Station.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_property_basic = pd.read_csv(property_dataset_path + csv_files[0])[\"ID\", \"price\", \"bedroom\", \"bathroom\", \"parking\", \"proType\", \"sold_date\"]\n",
    "df_property_full = pd.read_csv(property_dataset_path + csv_files[1])[\"ID\", \"sold_date\", \"locality\", ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
